import streamlit as st
import pandas as pd
import io

# ==============================================================================
# FUNCTION 1: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ ‡∏à2 (J2 Report)
# ==============================================================================
def process_j2_report(uploaded_files):
    """
    Function based on the very first script.
    Merges files, cleans data, and filters by a specific list of materials.
    """
    # 1. Load and combine all uploaded raw data files (*.xls)
    dfs = []
    for file_obj in uploaded_files:
        try:
            source_workbook = pd.ExcelFile(file_obj)
            for i, sheet_name in enumerate(source_workbook.sheet_names):
                df = source_workbook.parse(sheet_name, header=None)
                if i == 0:
                    df = df.iloc[2:]
                dfs.append(df)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå {file_obj.name}: {e}")
            return None
    
    if not dfs:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        return None
        
    stacked_df = pd.concat(dfs, ignore_index=True)

    # 2. Basic data cleaning
    stacked_df = stacked_df.dropna(subset=[stacked_df.columns[12]])
    stacked_df[stacked_df.columns[12]] = pd.to_numeric(stacked_df[stacked_df.columns[12]], errors='coerce')
    stacked_df[stacked_df.columns[18]] = pd.to_numeric(stacked_df[stacked_df.columns[18]], errors='coerce')

    # 3. Rename columns
    new_column_labels = [
        "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤", "‡πÄ‡∏ß‡∏•‡∏≤", "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£", "VN / AN", "HN", "‡∏ä‡∏∑‡πà‡∏≠", "‡∏≠‡∏≤‡∏¢‡∏∏", 
        "‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå", "‡πÅ‡∏û‡∏ó‡∏¢‡πå", "Clinic", "Ward", "Material", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô", "‡∏´‡∏ô‡πà‡∏ß‡∏¢",
        "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢R", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ß‡∏°", "Store"
    ]
    if len(stacked_df.columns) != len(new_column_labels):
        st.error(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ {len(new_column_labels)} ‡πÅ‡∏ï‡πà‡∏û‡∏ö {len(stacked_df.columns)}")
        return None
    stacked_df.columns = new_column_labels

    # 4. Filter for specific J2 materials
    valid_material_values = [
        1400000010, 1400000020, 1400000021, 1400000025, 1400000029, 
        1400000030, 1400000040, 1400000044, 1400000052, 1400000053, 
        1400000055, 1400000098, 1400000099, 1400000148, 1400000187, 
        1400000201, 1400000220, 1400000221, 1400000228, 1400000247, 
        1400000264, 1400000068, 1400000069, 1400000093, 1400000106, 
        1400000113, 1400000115, 1400000116, 1400000118, 1400000124, 
        1400000126, 1400000130, 1400000165, 1400000166, 1400000167, 
        1400000168, 1400000169, 1400000170, 1400000171, 1400000172, 
        1400000194, 1400000284, 1400000288, 1400000294, 1400000295, 
        1400000331, 1400000335, 1400000344, 1400000345, 1400000265
    ]
    merged_df = stacked_df[stacked_df["Material"].isin(valid_material_values)].copy()

    # 5. Select and reorder the final columns
    final_cols = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤', 'VN / AN', 'HN', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå', "‡πÅ‡∏û‡∏ó‡∏¢‡πå", 'Material', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô']
    merged_df = merged_df[final_cols]

    return merged_df

# ==============================================================================
# FUNCTION 2: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (Drug Rate Analysis)
# ==============================================================================
def process_drug_rate_analysis(data_files, master_file):
    """
    Function based on the second script with Drug Master file.
    Merges data, performs extensive analysis, and generates multiple pivot tables.
    """
    # 1. Load and combine all uploaded raw data files (*.xls)
    dfs = []
    for file_obj in data_files:
        try:
            source_workbook = pd.ExcelFile(file_obj)
            for i, sheet_name in enumerate(source_workbook.sheet_names):
                df = source_workbook.parse(sheet_name, header=None)
                if i == 0:
                    df = df.iloc[2:]
                dfs.append(df)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå {file_obj.name}: {e}")
            return None, {}

    if not dfs:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        return None, {}
    
    stacked_df = pd.concat(dfs, ignore_index=True)

    # 2. Load the Drug Master file
    try:
        dfmaster = pd.read_excel(master_file, sheet_name="Drug master")
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏µ‡∏ó 'Drug master' ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Master ‡πÑ‡∏î‡πâ: {e}")
        return None, {}

    # 3. Data Cleaning and Preprocessing
    stacked_df = stacked_df.dropna(subset=[stacked_df.columns[12]])
    stacked_df[stacked_df.columns[12]] = pd.to_numeric(stacked_df[stacked_df.columns[12]], errors='coerce')
    stacked_df[stacked_df.columns[18]] = pd.to_numeric(stacked_df[stacked_df.columns[18]], errors='coerce')
    
    new_column_labels = [
        "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤", "‡πÄ‡∏ß‡∏•‡∏≤", "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£", "VN / AN", "HN", "‡∏ä‡∏∑‡πà‡∏≠", "‡∏≠‡∏≤‡∏¢‡∏∏", 
        "‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå", "‡πÅ‡∏û‡∏ó‡∏¢‡πå", "Clinic", "Ward", "Material", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô", "‡∏´‡∏ô‡πà‡∏ß‡∏¢",
        "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢R", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ß‡∏°", "Store"
    ]
    if len(stacked_df.columns) != len(new_column_labels):
        st.error(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ {len(new_column_labels)} ‡πÅ‡∏ï‡πà‡∏û‡∏ö {len(stacked_df.columns)}")
        return None, {}
    stacked_df.columns = new_column_labels

    # 4. Merging and Transformations
    merged_df = pd.merge(stacked_df, dfmaster, on="Material", how="left")
    
    # FIX for FutureWarning: Change dtype to 'object' to allow mixed types
    merged_df['Store'] = merged_df['Store'].astype('object')
    
    valid_store_values = [2403, 2401, 2408, 2409, 2417, 2402]
    merged_df.loc[~merged_df["Store"].isin(valid_store_values), "Store"] = "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"
    
    merged_df["‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°"] = pd.to_numeric(merged_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"], errors='coerce') * pd.to_numeric(merged_df["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô"], errors='coerce')
    merged_df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤'] = pd.to_datetime(merged_df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤'], errors='coerce')
    merged_df['Month'] = merged_df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤'].dt.to_period('M')
    merged_df = merged_df[merged_df['Store'] != "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"]

    # --- Mapping '‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå' (example, full dictionary should be here) ---
    direct_map = { '(‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏µ‡πà‡∏£‡∏û.‡∏à‡∏∏‡∏¨‡∏≤‡∏†‡∏£‡∏ì‡πå) ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á‡∏õ‡∏≤‡∏Å‡∏°‡∏î‡∏•‡∏π‡∏Å ‡∏ì ‡∏£‡∏û.‡∏à‡∏∏‡∏¨‡∏≤‡∏†‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ì‡∏∞‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ß‡∏ä‡∏¥‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•': '‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏≠‡∏á', '[TopUp] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏ä‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏à‡∏∏‡∏¨‡∏≤‡∏†‡∏£‡∏ì‡πå': '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà', '‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô‡∏ö‡∏≥‡∏ô‡∏≤‡∏ç(‡πÄ‡∏ö‡∏¥‡∏Å‡∏à‡πà‡∏≤‡∏¢‡∏ï‡∏£‡∏á)': '‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£'}
    merged_df["‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå"] = merged_df["‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå"].map(direct_map).fillna(merged_df["‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå"])
    
    # 5. Data Splitting and Unique Counts (OPD/IPD)
    opd_merged_df = merged_df[merged_df['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£'].isna() | (merged_df['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£'].astype(str).str.strip().isin(['', '0']))]
    opd_2409 = opd_merged_df[opd_merged_df['Store'].notna() & (opd_merged_df['Store'] == 2409)]
    opd_not_2409 = opd_merged_df[opd_merged_df['Store'].notna() & (opd_merged_df['Store'] != 2409)]
    
    ipd_merged_df = merged_df[merged_df['Clinic'].isna() | (merged_df['Clinic'].astype(str).str.strip().isin(['', '0']))]
    ipd_2409 = ipd_merged_df[ipd_merged_df['Store'].notna() & (ipd_merged_df['Store'] == 2409)]
    ipd_not_2409 = ipd_merged_df[ipd_merged_df['Store'].notna() & (ipd_merged_df['Store'] != 2409)]
    
    def count_unique_by_month(df, subset_cols):
        return df.drop_duplicates(subset=subset_cols).groupby('Month').size().reset_index(name='Unique_Count')

    uniqueOPD = count_unique_by_month(opd_not_2409, ['VN / AN', 'HN', 'Clinic', 'Month'])
    uniqueOPD2409 = count_unique_by_month(opd_2409, ['VN / AN', 'HN', 'Clinic', 'Month'])
    uniqueIPD = count_unique_by_month(ipd_not_2409, ['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£', 'HN', 'Ward', 'Month'])
    uniqueIPD2409 = count_unique_by_month(ipd_2409, ['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£', 'HN', 'Ward', 'Month'])

    # 6. Final Cleaning and Pivot Table Generation
    merged_df["‡∏´‡∏ô‡πà‡∏ß‡∏¢"] = pd.to_numeric(merged_df["‡∏´‡∏ô‡πà‡∏ß‡∏¢"].astype(str).str.replace(r'.*/ ', '', regex=True), errors='coerce').fillna(1).astype(int)
    merged_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"] = merged_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"] * merged_df["‡∏´‡∏ô‡πà‡∏ß‡∏¢"]
    merged_df['HN'] = merged_df['HN'].astype(str).str.replace('.0', '', regex=False)

    grouped_countHN_df = merged_df.pivot_table(index=['Material', 'Material description'], columns='Month', values='HN', aggfunc=pd.Series.nunique).reset_index()
    grouped_sumRate_df = merged_df.pivot_table(index=['Material', 'Material description', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢'], columns='Month', values='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', aggfunc='sum').reset_index()
    grouped_sumRateSplit_df = merged_df.pivot_table(index=['Material', "Store", 'Material description', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢'], columns='Month', values='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', aggfunc='sum').reset_index()

    output_dfs = {
        "Rate ‡πÅ‡∏¢‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": grouped_sumRate_df,
        "Rate (M-Sloc)": grouped_sumRateSplit_df,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": grouped_countHN_df,
        "Raw": merged_df,
        "Summary_Data": {
            '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏¢‡∏≤ OPD': uniqueOPD, '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏¢‡∏≤ OPD 2409': uniqueOPD2409,
            '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏¢‡∏≤ IPD': uniqueIPD, '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏¢‡∏≤ IPD 2409': uniqueIPD2409,
        }
    }
    
    return merged_df, output_dfs

# ==============================================================================
# FUNCTION 3: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ EPI (EPI Usage Report)
# ==============================================================================
def process_epi_usage(uploaded_files):
    """
    Processes uploaded files to generate a summary of EPI drug usage.
    """
    # 1. Load and combine all uploaded raw data files (*.xls)
    dfs = []
    for file_obj in uploaded_files:
        try:
            source_workbook = pd.ExcelFile(file_obj)
            for i, sheet_name in enumerate(source_workbook.sheet_names):
                df = source_workbook.parse(sheet_name, header=None)
                if i == 0:
                    df = df.iloc[2:]
                dfs.append(df)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå {file_obj.name}: {e}")
            return None

    if not dfs:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        return None
    
    stacked_df = pd.concat(dfs, ignore_index=True)

    # 2. Basic data cleaning
    stacked_df = stacked_df.dropna(subset=[stacked_df.columns[12]])
    stacked_df[stacked_df.columns[12]] = pd.to_numeric(stacked_df[stacked_df.columns[12]], errors='coerce')
    stacked_df[stacked_df.columns[18]] = pd.to_numeric(stacked_df[stacked_df.columns[18]], errors='coerce')
    
    # 3. Rename columns
    new_column_labels = [
        "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤", "‡πÄ‡∏ß‡∏•‡∏≤", "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£", "VN / AN", "HN", "‡∏ä‡∏∑‡πà‡∏≠", "‡∏≠‡∏≤‡∏¢‡∏∏", 
        "‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå", "‡πÅ‡∏û‡∏ó‡∏¢‡πå", "Clinic", "Ward", "Material", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô", "‡∏´‡∏ô‡πà‡∏ß‡∏¢",
        "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢R", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ß‡∏°", "Store"
    ]
    if len(stacked_df.columns) != len(new_column_labels):
        st.error(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ {len(new_column_labels)} ‡πÅ‡∏ï‡πà‡∏û‡∏ö {len(stacked_df.columns)}")
        return None
    stacked_df.columns = new_column_labels

    # 4. Filter for specific EPI materials
    valid_epi_materials = [
        1400000084, 1400000083, 1400000087, 1400000086, 1400000088,
        1400000081, 1400000082, 1400000090, 1400000085, 1400000089
    ]
    epi_df = stacked_df[stacked_df["Material"].isin(valid_epi_materials)].copy()

    # 5. Group by Material and sum the quantity
    summary_df = epi_df.groupby(['Material', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤'])['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô'].sum().reset_index()
    summary_df.rename(columns={'‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°'}, inplace=True)
    
    return summary_df

# ==============================================================================
# STREAMLIT USER INTERFACE (UI)
# ==============================================================================
st.set_page_config(layout="wide")

st.sidebar.title("‚öôÔ∏è ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π")
app_mode = st.sidebar.selectbox(
    "‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:",
    ["‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å", "1. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ ‡∏à2", "2. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", "3. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ EPI"]
)

if app_mode == "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å":
    st.title("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    st.markdown("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏ô‡∏π‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
    st.markdown("- **1. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ ‡∏à2**: ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡∏¢‡∏≤‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (J2)")
    st.markdown("- **2. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡πÇ‡∏î‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÑ‡∏ü‡∏•‡πå Master")
    st.markdown("- **3. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ EPI**: ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ EPI")

elif app_mode == "1. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ ‡∏à2":
    st.title("Tool 1: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ ‡∏à2")
    st.info("‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (.xls) ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏à2")

    uploaded_files_j2 = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (*.xls)",
        type="xls", accept_multiple_files=True, key="j2_uploader"
    )
    
    if st.button("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏à2", key="j2_button"):
        if uploaded_files_j2:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                final_df = process_j2_report(uploaded_files_j2)
            if final_df is not None:
                st.success("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                st.dataframe(final_df)
                output_buffer = io.BytesIO()
                with pd.ExcelWriter(output_buffer, engine='xlsxwriter') as writer:
                    final_df.to_excel(writer, sheet_name='Raw', index=False)
                st.download_button(
                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå J2.xlsx", data=output_buffer.getvalue(),
                    file_name="J2.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

elif app_mode == "2. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô":
    st.title("Tool 2: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
    st.info("‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (.xls) ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå Drug Master (.xlsx)")

    col1, col2 = st.columns(2)
    with col1:
        uploaded_files_raw = st.file_uploader(
            "1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (*.xls)",
            type="xls", accept_multiple_files=True, key="raw_uploader"
        )
    with col2:
        master_file = st.file_uploader(
            "2. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Drug Master (*.xlsx)",
            type=["xlsx"], key="master_uploader"
        )
        
    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", key="analysis_button"):
        if uploaded_files_raw and master_file:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                raw_df, output_dfs = process_drug_rate_analysis(uploaded_files_raw, master_file)
            if raw_df is not None:
                st.success("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                output_buffer = io.BytesIO()
                with pd.ExcelWriter(output_buffer, engine='xlsxwriter') as writer:
                    for sheet_name, df_to_save in output_dfs.items():
                        if sheet_name != "Summary_Data":
                            df_to_save.to_excel(writer, sheet_name=sheet_name, index=False)
                    startrow = 0
                    for label, df_summary in output_dfs["Summary_Data"].items():
                        summary_pivot = df_summary.set_index('Month').T
                        summary_pivot.index = [label]
                        summary_pivot.to_excel(writer, sheet_name='Summary', startrow=startrow)
                        startrow += summary_pivot.shape[0] + 2
                st.download_button(
                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (Drugstore_Rate.xlsx)", data=output_buffer.getvalue(),
                    file_name="Drugstore_Rate.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                st.subheader("üìä ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
                tab1, tab2, tab3 = st.tabs(["Rate by Month", "Cases per Month", "Raw Merged Data"])
                with tab1: st.dataframe(output_dfs["Rate ‡πÅ‡∏¢‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"])
                with tab2: st.dataframe(output_dfs["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"])
                with tab3: st.dataframe(raw_df)
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå Drug Master")

elif app_mode == "3. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ EPI":
    st.title("Tool 3: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤ EPI")
    st.info("‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (.xls) ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤ EPI ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")

    uploaded_files_epi = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (*.xls)",
        type="xls", accept_multiple_files=True, key="epi_uploader"
    )
    
    if st.button("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô EPI", key="epi_button"):
        if uploaded_files_epi:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                final_df = process_epi_usage(uploaded_files_epi)
            if final_df is not None:
                st.success("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                st.subheader("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡πÉ‡∏ä‡πâ‡∏¢‡∏≤ EPI")
                st.dataframe(final_df)
                output_buffer = io.BytesIO()
                with pd.ExcelWriter(output_buffer, engine='xlsxwriter') as writer:
                    final_df.to_excel(writer, sheet_name='Raw', index=False)
                st.download_button(
                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå EPI usage.xlsx", data=output_buffer.getvalue(),
                    file_name="EPI usage.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            